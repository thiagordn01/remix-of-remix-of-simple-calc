import { useState, useCallback, useEffect, useRef } from "react";
import { useToast } from "@/hooks/use-toast";
import { GeminiTtsJob, JobLog } from "@/types/geminiTts";
import { buildGeminiApiUrl, GEMINI_TTS_MODEL } from "@/utils/geminiTtsConfig";
import { convertPcmToWav } from "@/utils/pcmToWav";
import { convertWavToMp3 } from "@/utils/wavToMp3";
import { decodeToBuffer, concatAudioBuffers, audioBufferToWav } from "@/utils/audioUtils";
import { useGeminiTtsKeys } from "@/hooks/useGeminiTtsKeys";
import { splitTextForGeminiTts, countWords } from "@/utils/geminiTtsChunks";

// ‚úÖ CORRE√á√ÉO: Lock global por requisi√ß√£o individual (n√£o apenas por job)
// Garante que mesma API key n√£o processe m√∫ltiplas requisi√ß√µes simultaneamente
const ACTIVE_REQUESTS = new Map<string, string>(); // keyId -> requestId (jobId:chunkIndex)

/**
 * Tenta adquirir lock para usar uma API key em uma requisi√ß√£o espec√≠fica
 * @returns true se conseguiu lock, false se key j√° est√° em uso
 */
function tryAcquireKeyLock(keyId: string, requestId: string): boolean {
  if (ACTIVE_REQUESTS.has(keyId)) {
    const currentRequest = ACTIVE_REQUESTS.get(keyId);
    console.log(`   üîí Key ${keyId.slice(0,8)} j√° est√° processando requisi√ß√£o: ${currentRequest}`);
    return false;
  }
  ACTIVE_REQUESTS.set(keyId, requestId);
  console.log(`   üîì Lock adquirido: Key ${keyId.slice(0,8)} ‚Üí ${requestId}`);
  return true;
}

/**
 * Libera lock de uma API key
 */
function releaseKeyLock(keyId: string, requestId: string): void {
  const currentRequest = ACTIVE_REQUESTS.get(keyId);
  if (currentRequest === requestId) {
    ACTIVE_REQUESTS.delete(keyId);
    console.log(`   ‚úÖ Lock liberado: Key ${keyId.slice(0,8)} (era ${requestId})`);
  }
}

// Fun√ß√£o auxiliar para atualizar um job espec√≠fico de forma segura
const updateJobState = (
  setJobs: React.Dispatch<React.SetStateAction<GeminiTtsJob[]>>,
  jobId: string,
  updates: Partial<GeminiTtsJob>,
) => {
  setJobs((prevJobs) => prevJobs.map((j) => (j.id === jobId ? { ...j, ...updates } : j)));
};

/**
 * Adiciona um log ao job
 * ‚úÖ OTIMIZADO: Usa batching impl√≠cito do React 18
 */
const addJobLog = (
  setJobs: React.Dispatch<React.SetStateAction<GeminiTtsJob[]>>,
  jobId: string,
  type: JobLog['type'],
  message: string,
  chunkIndex?: number
) => {
  try {
    setJobs((prevJobs) => {
      const updatedJobs = prevJobs.map((j) => {
        if (j.id !== jobId) return j;

        const log: JobLog = {
          timestamp: Date.now(),
          type,
          message,
          chunkIndex
        };

        const currentLogs = j.progressDetails?.logs || [];

        // Limitar a 50 logs para evitar memory leak
        const updatedLogs = [...currentLogs, log].slice(-50);

        // Console log para debug (remover em produ√ß√£o)
        console.log(`[LOG ${type.toUpperCase()}] ${message}`);

        // ‚úÖ CORRE√á√ÉO: Garantir que progressDetails sempre exista
        return {
          ...j,
          progressDetails: {
            phase: j.progressDetails?.phase || 'generating',
            phaseProgress: j.progressDetails?.phaseProgress || 0,
            currentChunkTotal: j.progressDetails?.currentChunkTotal || j.chunks.length,
            startTime: j.progressDetails?.startTime || Date.now(),
            chunkTimes: j.progressDetails?.chunkTimes || [],
            logs: updatedLogs,
            ...(j.progressDetails || {})
          }
        };
      });

      return updatedJobs;
    });
  } catch (error) {
    console.error('Erro ao adicionar log:', error);
  }
};

export function useGeminiTtsQueue(maxConcurrentJobs = 2) {
  const [jobs, setJobs] = useState<GeminiTtsJob[]>([]);
  const { toast } = useToast();
  const activeJobsCount = useRef(0);
  const queue = useRef<string[]>([]);
  const { 
    apiKeys, 
    getNextValidKey, 
    markKeyUsed, 
    markKeyNoCredits,
    reserveKeyForJob,
    releaseKeyFromJob
  } = useGeminiTtsKeys();

  // ADD THIS REF TO HOLD THE LATEST JOBS STATE
  const jobsRef = useRef(jobs);
  useEffect(() => {
    jobsRef.current = jobs;
  }, [jobs]);

  const processQueue = useCallback(async () => {
    if (activeJobsCount.current >= maxConcurrentJobs || queue.current.length === 0) {
      return;
    }

    const jobIdToProcess = queue.current.shift();
    if (!jobIdToProcess) return;

    // --- THIS IS THE FIX ---
    // Find the job using the ref, which is always up-to-date, instead of the async setter pattern
    const jobToProcess = jobsRef.current.find((j) => j.id === jobIdToProcess);

    if (!jobToProcess) {
      console.error(`[QUEUE] Job ${jobIdToProcess} n√£o encontrado. Pode ter sido removido.`);
      // N√£o recoloca na fila para evitar loops infinitos se o job foi deletado.
      return;
    }

    activeJobsCount.current++;

    // Reservar key EXCLUSIVA para este job
    console.log(`üöÄ Iniciando job ${jobToProcess.filename} (${jobToProcess.chunks.length} chunks)`);

    // ‚úÖ LOG: Job iniciado
    addJobLog(setJobs, jobToProcess.id, 'info', `Iniciando processamento de ${jobToProcess.chunks.length} chunks`);

    const dedicatedKey = getNextValidKey([], jobToProcess.id);

    if (!dedicatedKey) {
      console.error(`‚ùå [JOB ${jobToProcess.id.slice(0,8)}] Nenhuma key dispon√≠vel. Jobs em andamento: ${activeJobsCount.current - 1}`);
      
      updateJobState(setJobs, jobToProcess.id, { 
        status: "error", 
        error: `Todas as API keys est√£o em uso. Aguarde ${activeJobsCount.current - 1} job(s) em andamento terminarem.` 
      });
      
      toast({
        title: "Aguardando API keys",
        description: `Job "${jobToProcess.filename}" na fila. ${activeJobsCount.current - 1} jobs processando.`,
        variant: "default",
      });
      
      activeJobsCount.current--;
      processQueue();
      return;
    }

    reserveKeyForJob(dedicatedKey.id, jobToProcess.id);

    updateJobState(setJobs, jobToProcess.id, {
      status: "processing",
      progress: 5,
      currentApiKeyId: dedicatedKey.id,
      progressDetails: {
        ...jobToProcess.progressDetails!,
        phase: 'generating',
        phaseProgress: 0,
        currentApiKeyLabel: dedicatedKey.label
      }
    });

    // ### IN√çCIO DA CORRE√á√ÉO PRINCIPAL ###

    const generatedAudioChunks: (Blob | null)[] = new Array(jobToProcess.chunks.length).fill(null);

    const processChunkWithRetry = async (
      chunkIndex: number,
      currentRetry: number = 0,
      failedKeyIds: string[] = [],
      rateLimitedKeys: Map<string, number> = new Map(), // ‚úÖ NOVO: Rastrear keys com 429 e quando ficam dispon√≠veis
      chunkStartTime: number = Date.now() // ‚úÖ NOVO: Rastrear tempo total do chunk
    ): Promise<Blob> => {
      const chunk = jobToProcess!.chunks[chunkIndex];
      const totalChunks = jobToProcess!.chunks.length;
      const requestId = `${jobToProcess!.id.slice(0,8)}:chunk${chunkIndex}`;

      // ‚úÖ LOG: In√≠cio do retry
      if (currentRetry > 0) {
        console.log(`\nüîÅ [RETRY ${currentRetry}] Chunk ${chunkIndex + 1} - Elapsed: ${Math.floor((Date.now() - chunkStartTime) / 1000)}s`);
      }

      // ‚úÖ TIMEOUT GLOBAL: M√°ximo 10 minutos por chunk
      const MAX_CHUNK_TIME_MS = 10 * 60 * 1000; // 10 minutos
      const elapsedTime = Date.now() - chunkStartTime;
      if (elapsedTime > MAX_CHUNK_TIME_MS) {
        const elapsedMinutes = Math.floor(elapsedTime / 60000);
        throw new Error(
          `‚è±Ô∏è TIMEOUT: Chunk ${chunkIndex + 1} ultrapassou limite de ${MAX_CHUNK_TIME_MS / 60000} minutos ` +
          `(tentou por ${elapsedMinutes} minutos). Todas as APIs podem estar com rate limit prolongado.`
        );
      }

      // Calcular max retries baseado em APIs DISPON√çVEIS (n√£o reservadas e ativas)
      const totalActiveKeys = apiKeys.filter(k =>
        k.isActive &&
        k.status !== 'suspended' &&
        k.status !== 'no_credits'
      ).length;

      // ‚úÖ CORRE√á√ÉO: Limitar retries para evitar loop infinito (m√°ximo 20 tentativas)
      const MAX_CHUNK_RETRIES = Math.min(Math.max(totalActiveKeys * 2, 5), 20);

      // ‚úÖ CORRE√á√ÉO: Buscar key que N√ÉO esteja com lock ativo
      let apiKeyObj = null;
      let selectedKeyId: string | null = null;

      // Buscar todas as keys dispon√≠veis (excluindo falhadas, reservadas e em rate limit)
      const now = Date.now();
      const availableKeys = apiKeys.filter(k =>
        k.isActive &&
        k.status !== 'suspended' &&
        k.status !== 'no_credits' &&
        k.status !== 'invalid' &&
        !failedKeyIds.includes(k.id) &&
        // ‚úÖ NOVO: Excluir keys que ainda est√£o em cooldown
        (!rateLimitedKeys.has(k.id) || rateLimitedKeys.get(k.id)! <= now)
      );

      // Tentar adquirir lock em uma key dispon√≠vel
      for (const key of availableKeys) {
        if (tryAcquireKeyLock(key.id, requestId)) {
          apiKeyObj = key;
          selectedKeyId = key.id;
          break;
        }
      }

      if (!apiKeyObj || !selectedKeyId) {
        // ‚úÖ CR√çTICO: Se n√£o encontrou key, verificar se h√° keys em cooldown
        const totalKeys = apiKeys.filter(k => k.isActive).length;
        const keysInCooldown = apiKeys.filter(k =>
          k.isActive &&
          rateLimitedKeys.has(k.id) &&
          rateLimitedKeys.get(k.id)! > now &&
          !failedKeyIds.includes(k.id) // Excluir keys que falharam permanentemente
        ).length;
        const keysFailed = failedKeyIds.length;

        console.log(`‚ö†Ô∏è [RETRY ${currentRetry + 1}] Nenhuma key dispon√≠vel - Total: ${totalKeys}, Cooldown: ${keysInCooldown}, Falhadas: ${keysFailed}`);

        if (keysInCooldown > 0) {
          // ‚úÖ H√Å KEYS EM COOLDOWN - AGUARDAR AT√â A PR√ìXIMA FICAR DISPON√çVEL
          const nextAvailable = Math.min(
            ...Array.from(rateLimitedKeys.values()).filter(t => t > now)
          );
          const waitMs = nextAvailable - now;
          const waitSec = Math.ceil(waitMs / 1000);

          console.warn(`‚è∏Ô∏è TODAS as ${keysInCooldown} keys em cooldown! Aguardando ${waitSec}s at√© pr√≥xima ficar dispon√≠vel...`);

          addJobLog(setJobs, jobToProcess.id, 'warning',
            `‚è∏Ô∏è Aguardando ${waitSec}s at√© pr√≥xima API ficar dispon√≠vel...`,
            chunkIndex
          );

          // ‚è±Ô∏è PROFILING: Marcar in√≠cio da espera
          const waitStartTime = Date.now();
          console.log(`   ‚è±Ô∏è [${new Date().toLocaleTimeString()}] Iniciando espera de ${waitSec}s por cooldown...`);

          // ‚úÖ AGUARDAR + margem de 1s
          await new Promise(resolve => setTimeout(resolve, waitMs + 1000));

          const actualWaitTime = Date.now() - waitStartTime;
          console.log(`   ‚è±Ô∏è Espera conclu√≠da: ${(actualWaitTime / 1000).toFixed(1)}s`);

          // ‚úÖ LIMPAR keys que sa√≠ram do cooldown
          const nowAfterWait = Date.now();
          let keysCleared = 0;
          for (const [keyId, availableAt] of rateLimitedKeys.entries()) {
            if (availableAt <= nowAfterWait) {
              rateLimitedKeys.delete(keyId);
              keysCleared++;
              console.log(`‚úÖ Key ${keyId.slice(0, 8)} saiu do cooldown`);
            }
          }

          console.log(`‚úÖ ${keysCleared} key(s) dispon√≠vel(is) novamente. Tentando retry...`);

          // ‚úÖ FAZER RETRY (n√£o lan√ßar erro, apenas tentar novamente)
          return processChunkWithRetry(chunkIndex, currentRetry, failedKeyIds, rateLimitedKeys, chunkStartTime);
        }

        // ‚úÖ SEM KEYS EM COOLDOWN = Todas falharam permanentemente
        const errorMsg = `‚ùå Nenhuma API key dispon√≠vel - Total: ${totalKeys}, Falhadas: ${keysFailed}. ` +
          `Todas as keys dispon√≠veis falharam. Adicione mais API keys ou verifique as configura√ß√µes.`;

        addJobLog(setJobs, jobToProcess.id, 'error', errorMsg, chunkIndex);
        throw new Error(errorMsg);
      }

      // Log apenas a cada 5 chunks para reduzir bloqueio de UI
      if (chunkIndex % 5 === 0 || currentRetry > 0) {
        console.log(`üîÑ Chunk ${chunkIndex + 1}/${totalChunks} | Tentativa ${currentRetry + 1}`);
      }

      updateJobState(setJobs, jobToProcess!.id, {
        currentChunk: chunkIndex,
        progress: Math.floor(((chunkIndex + 0.25) / totalChunks) * 100),
        currentApiKeyId: apiKeyObj.id,
      });

      try {
        const apiUrl = buildGeminiApiUrl(apiKeyObj.key);

        const chunkWords = countWords(chunk);
        console.log(`   ‚è≥ Chunk ${chunkIndex + 1}/${jobToProcess!.chunks.length}: Requisitando ${chunkWords} palavras para Gemini TTS...`);

        const requestBody = {
          model: GEMINI_TTS_MODEL,
          contents: [{ parts: [{ text: chunk }] }],
          generationConfig: {
            responseModalities: ["AUDIO"],
            speechConfig: {
              voiceConfig: { prebuiltVoiceConfig: { voiceName: jobToProcess!.voiceName } },
            },
          },
        };

        // ‚è±Ô∏è PROFILING: Medir tempo de resposta da API Gemini
        const apiStartTime = Date.now();
        console.log(`   ‚è±Ô∏è [${new Date().toLocaleTimeString()}] Enviando requisi√ß√£o para Gemini...`);

        const response = await fetch(apiUrl, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(requestBody),
        });

        const apiResponseTime = Date.now() - apiStartTime;
        console.log(`   ‚è±Ô∏è API Gemini respondeu em ${(apiResponseTime / 1000).toFixed(2)}s (${apiResponseTime}ms)`);

        if (response.status === 429 || response.status === 402 || response.status === 403) {
          const errorMsg = `API Error ${response.status}`;

          console.warn(`‚ö†Ô∏è Key "${apiKeyObj.label}" falhou - Status ${response.status}`);

          // ‚úÖ NOVO: Para erro 429, parsear RetryInfo do Google
          if (response.status === 429) {
            try {
              const errorData = await response.json();
              const retryInfo = errorData.error?.details?.find((d: any) =>
                d['@type']?.includes('RetryInfo')
              );

              let retryDelaySeconds = 60; // Padr√£o: 60 segundos
              if (retryInfo?.retryDelay) {
                const match = retryInfo.retryDelay.match(/(\d+)/);
                if (match) {
                  retryDelaySeconds = parseInt(match[1], 10);
                }
              }

              const availableAt = Date.now() + (retryDelaySeconds * 1000);
              rateLimitedKeys.set(selectedKeyId!, availableAt);

              console.log(`‚è∏Ô∏è Key "${apiKeyObj.label}" em cooldown por ${retryDelaySeconds}s (dispon√≠vel √†s ${new Date(availableAt).toLocaleTimeString()})`);
              addJobLog(setJobs, jobToProcess.id, 'warning',
                `API "${apiKeyObj.label}" atingiu rate limit - aguardando ${retryDelaySeconds}s`,
                chunkIndex
              );
            } catch (e) {
              // Se falhar ao parsear, usar 60s padr√£o
              rateLimitedKeys.set(selectedKeyId!, Date.now() + 60000);
            }
          } else {
            // 402/403: sem cr√©ditos ou suspensa
            markKeyNoCredits(apiKeyObj.id);
            const updatedFailedKeys = [...failedKeyIds, selectedKeyId!];

            // ‚úÖ LIBERAR LOCK antes de retry
            releaseKeyLock(selectedKeyId!, requestId);

            if (currentRetry < MAX_CHUNK_RETRIES) {
              await new Promise((resolve) => setTimeout(resolve, 1000));
              return processChunkWithRetry(chunkIndex, currentRetry + 1, updatedFailedKeys, rateLimitedKeys, chunkStartTime);
            }

            throw new Error(`${errorMsg} - Todas as ${updatedFailedKeys.length} keys testadas falharam.`);
          }

          // ‚úÖ LIBERAR LOCK antes de retry
          releaseKeyLock(selectedKeyId!, requestId);

          // ‚úÖ FAZER RETRY - A l√≥gica de "aguardar todas em cooldown" j√° est√° na linha 245-290
          // quando tentamos pegar uma nova key
          if (currentRetry < MAX_CHUNK_RETRIES) {
            console.log(`üîÑ Retry ${currentRetry + 1}/${MAX_CHUNK_RETRIES} ap√≥s 429 da key "${apiKeyObj.label}"`);
            // ‚è±Ô∏è Aguardando 1s antes de tentar pr√≥xima key (dar tempo para rate limit registrar)
            await new Promise((resolve) => setTimeout(resolve, 1000));
            return processChunkWithRetry(chunkIndex, currentRetry + 1, failedKeyIds, rateLimitedKeys, chunkStartTime);
          }

          throw new Error(`Rate Limit: Atingiu m√°ximo de ${MAX_CHUNK_RETRIES} tentativas. Todas as keys podem estar em rate limit.`);
        }

        if (!response.ok) {
          const errorData = await response.json().catch(() => ({}));
          throw new Error(`Erro ${response.status}: ${errorData.error?.message || response.statusText}`);
        }

        markKeyUsed(apiKeyObj.id);

        // ‚è±Ô∏è PROFILING: Medir parse do JSON
        const parseStartTime = Date.now();
        const result = await response.json();
        const parseTime = Date.now() - parseStartTime;
        console.log(`   ‚è±Ô∏è Parse JSON: ${parseTime}ms`);

        const audioPart = result.candidates?.[0]?.content?.parts?.find((p: any) => p.inlineData);
        if (!audioPart?.inlineData?.data) {
          throw new Error("Nenhum √°udio recebido da API.");
        }

        // ‚úÖ LOG: Tamanho do base64 recebido da API
        const base64Size = audioPart.inlineData.data.length;
        const base64SizeKB = (base64Size / 1024).toFixed(2);
        console.log(`      ‚úÖ Resposta recebida: ${base64Size} chars base64 (${base64SizeKB} KB) - MimeType: ${audioPart.inlineData.mimeType}`);
        addJobLog(setJobs, jobToProcess.id, 'info', `API respondeu: ${base64SizeKB} KB base64`, chunkIndex);

        // ‚è±Ô∏è PROFILING: Medir convers√£o PCM to WAV
        const conversionStartTime = Date.now();
        const wavBytes = convertPcmToWav(audioPart.inlineData.data, audioPart.inlineData.mimeType);
        const conversionTime = Date.now() - conversionStartTime;

        if (wavBytes.length === 0) throw new Error("Falha ao converter √°udio.");

        const wavSizeMB = (wavBytes.length / (1024 * 1024)).toFixed(2);
        console.log(`      ‚úÖ WAV convertido: ${wavBytes.length} bytes (${wavSizeMB} MB) em ${conversionTime}ms`);
        addJobLog(setJobs, jobToProcess.id, 'success', `WAV gerado: ${wavSizeMB} MB`, chunkIndex);

        // ‚úÖ SUCESSO: Liberar lock e retornar blob
        releaseKeyLock(selectedKeyId!, requestId);
        return new Blob([wavBytes] as BlobPart[], { type: "audio/wav" });

      } catch (error) {
        const errorMsg = error instanceof Error ? error.message : String(error);
        const isKeyError = errorMsg.includes('429') || errorMsg.includes('402') || errorMsg.includes('403');

        // ‚úÖ GARANTIR que lock seja liberado em caso de erro
        releaseKeyLock(selectedKeyId!, requestId);

        if (isKeyError && currentRetry < MAX_CHUNK_RETRIES) {
          const updatedFailedKeys = failedKeyIds.includes(selectedKeyId!)
            ? failedKeyIds
            : [...failedKeyIds, selectedKeyId!];

          await new Promise((resolve) => setTimeout(resolve, 2000));
          return processChunkWithRetry(chunkIndex, currentRetry + 1, updatedFailedKeys, rateLimitedKeys, chunkStartTime);
        }

        if (currentRetry < MAX_CHUNK_RETRIES) {
          await new Promise((resolve) => setTimeout(resolve, 2000));
          return processChunkWithRetry(chunkIndex, currentRetry + 1, failedKeyIds, rateLimitedKeys, chunkStartTime);
        }

        throw error;
      }
    };

    try {
      // ‚úÖ CORRE√á√ÉO: Processar chunks SEQUENCIALMENTE e refazer IMEDIATAMENTE se falhar
      console.log(`üîÑ [JOB ${jobToProcess.id.slice(0,8)}] Iniciando processamento de ${jobToProcess.chunks.length} chunks`);

      for (let i = 0; i < jobToProcess.chunks.length; i++) {
        const chunkWordCount = countWords(jobToProcess.chunks[i]);
        const chunkStartTime = Date.now();
        console.log(`\nüìù [CHUNK ${i + 1}/${jobToProcess.chunks.length}] Processando (${chunkWordCount} palavras)`);

        // ‚úÖ LOG: Iniciando chunk
        addJobLog(setJobs, jobToProcess.id, 'info', `Processando chunk ${i + 1}/${jobToProcess.chunks.length} (${chunkWordCount} palavras)`, i);

        let chunkSuccess = false;
        let lastChunkError = null;

        // ‚úÖ CORRE√á√ÉO: Tentar gerar chunk com retry agressivo (at√© 5 tentativas)
        const MAX_CHUNK_ATTEMPTS = 5;

        for (let attempt = 1; attempt <= MAX_CHUNK_ATTEMPTS && !chunkSuccess; attempt++) {
          try {
            console.log(`   üîÑ Tentativa ${attempt}/${MAX_CHUNK_ATTEMPTS} para chunk ${i + 1}`);

            // ‚úÖ LOG: Tentativa
            if (attempt > 1) {
              addJobLog(setJobs, jobToProcess.id, 'warning', `Retry ${attempt}/${MAX_CHUNK_ATTEMPTS} para chunk ${i + 1}`, i);
            }

            // ‚úÖ ATUALIZAR: Progresso detalhado com tentativa atual
            updateJobState(setJobs, jobToProcess.id, {
              currentChunk: i,
              progressDetails: {
                ...jobToProcess.progressDetails!,
                currentChunkAttempt: attempt,
                phaseProgress: Math.floor(((i + (attempt - 1) / MAX_CHUNK_ATTEMPTS) / jobToProcess.chunks.length) * 100)
              }
            });

            // Resetar lista de keys falhadas a cada nova tentativa (permite reusar keys)
            const wavBlob = await processChunkWithRetry(i, 0, []);
            generatedAudioChunks[i] = wavBlob;
            chunkSuccess = true;

            const chunkElapsedTime = Date.now() - chunkStartTime;
            console.log(`\n   ‚úÖ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê`);
            console.log(`   ‚úÖ Chunk ${i + 1}/${jobToProcess.chunks.length} CONCLU√çDO`);
            console.log(`   ‚úÖ Tempo total: ${(chunkElapsedTime / 1000).toFixed(2)}s`);
            console.log(`   ‚úÖ Palavras: ${chunkWordCount} | Tentativas: ${attempt}`);
            console.log(`   ‚úÖ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n`);

            // ‚úÖ LOG: Chunk conclu√≠do
            addJobLog(setJobs, jobToProcess.id, 'success', `Chunk ${i + 1} conclu√≠do: ${(chunkElapsedTime / 1000).toFixed(1)}s (${chunkWordCount} palavras)`, i);

            // Calcular tempo estimado restante
            const currentChunkTimes = jobToProcess.progressDetails?.chunkTimes || [];
            const updatedChunkTimes = [...currentChunkTimes, chunkElapsedTime];
            const avgChunkTime = updatedChunkTimes.reduce((a, b) => a + b, 0) / updatedChunkTimes.length;
            const remainingChunks = jobToProcess.chunks.length - (i + 1);
            const estimatedTimeRemaining = Math.ceil((avgChunkTime * remainingChunks) / 1000);

            // Atualizar progresso
            updateJobState(setJobs, jobToProcess.id, {
              progress: Math.floor(((i + 1) / jobToProcess.chunks.length) * 90), // 0-90%
              failedChunks: [],
              progressDetails: {
                ...jobToProcess.progressDetails!,
                chunkTimes: updatedChunkTimes,
                estimatedTimeRemaining,
                phaseProgress: Math.floor(((i + 1) / jobToProcess.chunks.length) * 100)
              }
            });

            // ‚úÖ YIELD: Deixa UI respirar entre chunks
            await new Promise(resolve => setTimeout(resolve, 0));

          } catch (chunkError: any) {
            lastChunkError = chunkError;
            console.warn(`   ‚ö†Ô∏è Chunk ${i + 1} falhou na tentativa ${attempt}: ${chunkError.message}`);

            // ‚úÖ LOG: Erro na chunk
            addJobLog(setJobs, jobToProcess.id, 'warning', `Chunk ${i + 1} falhou (tentativa ${attempt}): ${chunkError.message}`, i);

            // Adicionar delay progressivo entre tentativas (backoff exponencial)
            if (attempt < MAX_CHUNK_ATTEMPTS) {
              const delayMs = Math.min(1000 * Math.pow(2, attempt - 1), 5000); // 1s, 2s, 4s, 5s, 5s
              console.log(`   ‚è≥ Aguardando ${delayMs}ms antes de tentar novamente...`);
              await new Promise(resolve => setTimeout(resolve, delayMs));
            }
          }
        }

        // ‚úÖ CORRE√á√ÉO CR√çTICA: Se chunk falhou ap√≥s todas tentativas, PARAR IMEDIATAMENTE
        if (!chunkSuccess) {
          const errorMsg = `‚ùå FALHA CR√çTICA: Chunk ${i + 1}/${jobToProcess.chunks.length} falhou ap√≥s ${MAX_CHUNK_ATTEMPTS} tentativas. Erro: ${lastChunkError?.message || 'Desconhecido'}`;
          console.error(errorMsg);

          // ‚úÖ LOG: Falha cr√≠tica
          addJobLog(setJobs, jobToProcess.id, 'error', errorMsg, i);

          updateJobState(setJobs, jobToProcess.id, {
            failedChunks: [i],
            currentChunk: i,
          });

          throw new Error(errorMsg);
        }
      }

      console.log(`\n‚úÖ [JOB ${jobToProcess.id.slice(0,8)}] Todas as ${jobToProcess.chunks.length} chunks foram geradas com sucesso!`);

      // ‚úÖ LOG: Todas chunks geradas
      addJobLog(setJobs, jobToProcess.id, 'success', `Todas as ${jobToProcess.chunks.length} chunks geradas com sucesso!`);

      // ‚úÖ VALIDA√á√ÉO CR√çTICA: Verificar integridade ANTES de concatenar
      console.log(`\nüîç [VALIDA√á√ÉO] Verificando integridade dos ${jobToProcess.chunks.length} chunks...`);

      // ‚úÖ ATUALIZAR: Fase de valida√ß√£o
      updateJobState(setJobs, jobToProcess.id, {
        progressDetails: {
          ...jobToProcess.progressDetails!,
          phase: 'validating',
          phaseProgress: 0
        }
      });

      addJobLog(setJobs, jobToProcess.id, 'info', 'Validando integridade dos chunks...');

      // Valida√ß√£o 1: Nenhum chunk pode ser null
      const nullChunks = generatedAudioChunks
        .map((chunk, idx) => chunk === null ? idx : -1)
        .filter(idx => idx !== -1);

      if (nullChunks.length > 0) {
        throw new Error(`‚ùå ERRO CR√çTICO: ${nullChunks.length} chunk(s) est√£o null: [${nullChunks.join(', ')}]`);
      }

      // Valida√ß√£o 2: Todos os chunks devem ter tamanho > 0
      const emptyChunks = generatedAudioChunks
        .map((chunk, idx) => (chunk && chunk.size === 0) ? idx : -1)
        .filter(idx => idx !== -1);

      if (emptyChunks.length > 0) {
        throw new Error(`‚ùå ERRO CR√çTICO: ${emptyChunks.length} chunk(s) est√£o vazios: [${emptyChunks.join(', ')}]`);
      }

      // Valida√ß√£o 3: Verificar ordem sequencial (√≠ndices 0, 1, 2, ...)
      for (let i = 0; i < generatedAudioChunks.length; i++) {
        if (!generatedAudioChunks[i]) {
          throw new Error(`‚ùå ERRO CR√çTICO: Chunk ${i} est√° faltando na sequ√™ncia!`);
        }
      }

      console.log(`‚úÖ [VALIDA√á√ÉO] Todos os ${jobToProcess.chunks.length} chunks est√£o √≠ntegros e na ordem correta!`);

      // ‚úÖ LOG: Valida√ß√£o conclu√≠da
      addJobLog(setJobs, jobToProcess.id, 'success', 'Valida√ß√£o conclu√≠da: todos os chunks √≠ntegros');

      updateJobState(setJobs, jobToProcess.id, {
        progress: 90,
        status: "processing",
        progressDetails: {
          ...jobToProcess.progressDetails!,
          phase: 'concatenating',
          phaseProgress: 0
        }
      });

      // ‚úÖ SINCRONIZA√á√ÉO: Usar array original para manter ordem EXATA
      const orderedChunks = generatedAudioChunks as Blob[];
      console.log(`\nüîó [CONCATENA√á√ÉO] Iniciando concatena√ß√£o de ${orderedChunks.length} chunks...`);

      // ‚úÖ LOG: Iniciando concatena√ß√£o
      addJobLog(setJobs, jobToProcess.id, 'info', `Concatenando ${orderedChunks.length} chunks de √°udio...`);

      // 1. Converter Blobs para ArrayBuffers (mantendo ordem)
      console.log(`üîÑ [CONVERS√ÉO] Convertendo ${orderedChunks.length} Blobs ‚Üí ArrayBuffers...`);
      const arrayBuffers: ArrayBuffer[] = [];
      for (let idx = 0; idx < orderedChunks.length; idx++) {
        const arrayBuffer = await orderedChunks[idx].arrayBuffer();
        const sizeMB = (arrayBuffer.byteLength / (1024 * 1024)).toFixed(2);
        console.log(`   üì¶ Chunk ${idx + 1}/${orderedChunks.length}: ${arrayBuffer.byteLength} bytes (${sizeMB} MB)`);
        addJobLog(setJobs, jobToProcess.id, 'info', `Chunk ${idx + 1} blob: ${sizeMB} MB`, idx);

        arrayBuffers.push(arrayBuffer);

        // ‚úÖ YIELD a cada 3 chunks para n√£o travar UI
        if (idx % 3 === 0) {
          await new Promise(resolve => setTimeout(resolve, 0));
        }
      }
      console.log(`‚úÖ [CONVERS√ÉO] ${arrayBuffers.length} ArrayBuffers prontos!`);

      // 2. Decodificar para AudioBuffers
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const audioBuffers: AudioBuffer[] = [];

      try {
        console.log(`üìä [DECODIFICA√á√ÉO] Decodificando ${arrayBuffers.length} WAV files...`);
        addJobLog(setJobs, jobToProcess.id, 'info', `Decodificando ${arrayBuffers.length} chunks de √°udio...`);

        for (let index = 0; index < arrayBuffers.length; index++) {
          const decoded = await decodeToBuffer(arrayBuffers[index], audioContext);

          // ‚úÖ LOG CR√çTICO: Dura√ß√£o individual de cada chunk ANTES da concatena√ß√£o
          const chunkWords = countWords(jobToProcess.chunks[index]);
          const durationSeconds = decoded.duration.toFixed(2);
          const durationMinutes = (decoded.duration / 60).toFixed(2);
          console.log(`   üìù Chunk ${index + 1}/${arrayBuffers.length}: ${durationSeconds}s (${durationMinutes} min) - ${chunkWords} palavras`);
          addJobLog(setJobs, jobToProcess.id, 'info', `Chunk ${index + 1}: ${durationSeconds}s (${durationMinutes} min) - ${chunkWords} palavras`, index);

          audioBuffers.push(decoded);

          // ‚úÖ VALIDA√á√ÉO: Verificar sample rate consistente
          if (index === 0) {
            console.log(`   Sample Rate: ${decoded.sampleRate} Hz, Canais: ${decoded.numberOfChannels}, Dura√ß√£o: ${decoded.duration.toFixed(2)}s`);
          } else {
            const firstSampleRate = audioBuffers[0].sampleRate;
            if (decoded.sampleRate !== firstSampleRate) {
              throw new Error(`‚ùå ERRO DE SINCRONIZA√á√ÉO: Chunk ${index} tem sample rate ${decoded.sampleRate} Hz, mas chunk 0 tem ${firstSampleRate} Hz!`);
            }
          }

          // ‚úÖ YIELD a cada 2 chunks
          if (index % 2 === 0) {
            await new Promise(resolve => setTimeout(resolve, 0));
          }
        }

        console.log(`‚úÖ [DECODIFICA√á√ÉO] ${audioBuffers.length} chunks decodificados com sucesso!`);

        // ‚úÖ LOG: Decodifica√ß√£o conclu√≠da
        addJobLog(setJobs, jobToProcess.id, 'success', `${audioBuffers.length} chunks decodificados`);

        // 3. Concatenar AudioBuffers (com normaliza√ß√£o RMS autom√°tica)
        console.log(`üîó [CONCATENA√á√ÉO] Concatenando e normalizando volumes...`);
        addJobLog(setJobs, jobToProcess.id, 'info', 'Normalizando volumes e concatenando...');

        const concatenatedBuffer = concatAudioBuffers(audioBuffers);
        const totalDurationSeconds = concatenatedBuffer.duration.toFixed(2);
        const totalDurationMinutes = (concatenatedBuffer.duration / 60).toFixed(2);

        console.log(`‚úÖ [CONCATENA√á√ÉO] √Åudio final: ${totalDurationSeconds}s (${totalDurationMinutes} min) @ ${concatenatedBuffer.sampleRate} Hz`);

        // ‚úÖ LOG: Concatena√ß√£o conclu√≠da
        addJobLog(setJobs, jobToProcess.id, 'success', `√Åudio concatenado: ${totalDurationSeconds}s (${totalDurationMinutes} min)`);

        // ‚úÖ YIELD antes de convers√£o pesada
        await new Promise(resolve => setTimeout(resolve, 0));

        // 4. Re-encodar para WAV
        console.log(`üîÑ [ENCODING] Convertendo AudioBuffer ‚Üí WAV...`);

        // ‚úÖ ATUALIZAR: Fase de encoding
        updateJobState(setJobs, jobToProcess.id, {
          progressDetails: {
            ...jobToProcess.progressDetails!,
            phase: 'encoding',
            phaseProgress: 0
          }
        });

        addJobLog(setJobs, jobToProcess.id, 'info', 'Encoding para WAV...');

        const wavArrayBuffer = audioBufferToWav(concatenatedBuffer);
        const finalWavBlob = new Blob([wavArrayBuffer], { type: "audio/wav" });
        console.log(`‚úÖ [WAV] Arquivo WAV gerado: ${(finalWavBlob.size / 1024 / 1024).toFixed(2)} MB`);

        // ‚úÖ LOG: WAV gerado
        addJobLog(setJobs, jobToProcess.id, 'success', `WAV gerado: ${(finalWavBlob.size / 1024 / 1024).toFixed(2)} MB`);

        updateJobState(setJobs, jobToProcess.id, { progress: 95 });

        // ‚úÖ YIELD antes de MP3 (convers√£o mais pesada)
        await new Promise(resolve => setTimeout(resolve, 0));

        // 5. Converter para MP3
        console.log(`üéµ [MP3] Convertendo WAV ‚Üí MP3 (128 kbps)...`);

        // ‚úÖ ATUALIZAR: Fase de convers√£o MP3
        updateJobState(setJobs, jobToProcess.id, {
          progressDetails: {
            ...jobToProcess.progressDetails!,
            phase: 'converting',
            phaseProgress: 0
          }
        });

        addJobLog(setJobs, jobToProcess.id, 'info', 'Convertendo para MP3 (128 kbps)...');

        const mp3Blob = await convertWavToMp3(finalWavBlob);
        const mp3SizeMB = (mp3Blob.size / (1024 * 1024)).toFixed(2);
        console.log(`‚úÖ [MP3] Arquivo MP3 gerado: ${mp3SizeMB} MB`);

        const audioUrl = URL.createObjectURL(mp3Blob);
        console.log(`üéâ [SUCESSO] √Åudio completo dispon√≠vel!`);

        // ‚úÖ LOG: MP3 gerado e job completo
        addJobLog(setJobs, jobToProcess.id, 'success', `MP3 gerado: ${(mp3Blob.size / 1024 / 1024).toFixed(2)} MB`);

        updateJobState(setJobs, jobToProcess.id, {
          status: "done",
          audioUrl,
          progress: 100,
        });

        toast({
          title: "‚úÖ √Åudio gerado com sucesso!",
          description: `${jobToProcess.filename} - ${totalDurationMinutes} min (${jobToProcess.chunks.length} chunks concatenados)`,
          variant: "default",
        });

      } catch (concatError: any) {
        throw new Error(`Falha ao concatenar √°udio: ${concatError.message}`);
      } finally {
        // ‚úÖ IMPORTANTE: Fechar AudioContext para liberar mem√≥ria
        if (audioContext) {
          await audioContext.close();
        }
      }
    } catch (error: any) {
      console.error(`‚ùå Job ${jobToProcess.filename} falhou: ${error.message}`);
      updateJobState(setJobs, jobToProcess.id, { status: "error", error: error.message });
    } finally {
      // Liberar key reservada
      if (jobToProcess.currentApiKeyId) {
        releaseKeyFromJob(jobToProcess.currentApiKeyId, jobToProcess.id);
      }

      activeJobsCount.current--;
      processQueue();
    }
  }, [maxConcurrentJobs, toast, apiKeys, getNextValidKey, markKeyUsed, markKeyNoCredits]);

  const addJob = useCallback(
    (
      jobDetails: Omit<
        GeminiTtsJob,
        "id" | "status" | "progress" | "chunks" | "audioChunks" | "failedChunks" | "chunkRetries"
      >,
    ) => {
      const chunks = splitTextForGeminiTts(jobDetails.text);

      const newJob: GeminiTtsJob = {
        id: crypto.randomUUID(),
        status: "queued",
        progress: 0,
        chunks,
        audioChunks: new Array(chunks.length).fill(null),
        failedChunks: [],
        chunkRetries: {},
        ...jobDetails,
        filename: jobDetails.filename || `audio_${Date.now()}`,
        // ‚úÖ NOVO: Inicializar progresso detalhado
        progressDetails: {
          phase: 'chunking',
          phaseProgress: 0,
          currentChunkTotal: chunks.length,
          startTime: Date.now(),
          chunkTimes: [],
          logs: [{
            timestamp: Date.now(),
            type: 'info',
            message: `Job criado com ${chunks.length} chunks (${countWords(jobDetails.text)} palavras total)`
          }]
        }
      };

      setJobs((prev) => [...prev, newJob]);
      queue.current.push(newJob.id);
      // REMOVED: setTimeout(processQueue, 0); to prevent race conditions
      return newJob.id;
    },
    [],
  );

  useEffect(() => {
    // Tenta iniciar um novo job da fila sempre que a lista de jobs mudar
    // (por exemplo, quando um job √© adicionado)
    processQueue();
  }, [jobs, processQueue]);

  const removeJob = (id: string) => {
    const jobToRemove = jobs.find(j => j.id === id);

    // ‚úÖ N√£o permitir remover job em processamento (previne crash)
    if (jobToRemove?.status === "processing") {
      toast({
        title: "N√£o √© poss√≠vel remover",
        description: "Aguarde o job terminar antes de remover",
        variant: "destructive",
      });
      return;
    }

    // ‚úÖ Revogar Blob URL antes de remover para evitar memory leak
    if (jobToRemove?.audioUrl) {
      URL.revokeObjectURL(jobToRemove.audioUrl);
    }

    setJobs((prev) => prev.filter((j) => j.id !== id));
    queue.current = queue.current.filter((jobId) => jobId !== id);
  };

  const clearCompletedJobs = () => {
    // ‚úÖ Revogar Blob URLs ANTES de remover para evitar memory leak
    jobs.forEach(job => {
      if ((job.status === "done" || job.status === "error") && job.audioUrl) {
        URL.revokeObjectURL(job.audioUrl);
      }
    });

    setJobs((prev) => prev.filter((j) => j.status !== "done" && j.status !== "error"));
  };

  return { jobs, addJob, removeJob, clearCompletedJobs };
}
